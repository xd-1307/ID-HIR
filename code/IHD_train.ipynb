{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ID, HR\n",
    "from vgg import VGG\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "from dataset import Dataset\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "target = VGG('VGG16')\n",
    "pthfile = \"./VGG16_ckpt.pth\"\n",
    "d = torch.load(pthfile)['net']\n",
    "d = OrderedDict([(k[7:], v) for (k, v) in d.items()])\n",
    "target.load_state_dict(d)\n",
    "target = target.to(device)\n",
    "\n",
    "attackPath = [\"../defense/adv_data/cifar10/fgsm/0.015x_adv.npy\",\n",
    "              \"../defense/adv_data/cifar10/fgsm/0.03x_adv.npy\",\n",
    "              \"../defense/adv_data/cifar10/fgsm/0.06x_adv.npy\",\n",
    "              \"../defense/adv_data/cifar10/cw/0.015x_adv.npy\",\n",
    "              \"../defense/adv_data/cifar10/cw/0.03x_adv.npy\",\n",
    "              \"../defense/adv_data/cifar10/cw/0.06x_adv.npy\",\n",
    "              \"../defense/adv_data/cifar10/bim/0.015x_adv.npy\",\n",
    "              \"../defense/adv_data/cifar10/bim/0.03x_adv.npy\",\n",
    "              \"../defense/adv_data/cifar10/bim/0.06x_adv.npy\"\n",
    "              ]\n",
    "cleanPath = \"./data/cifar10_data.npy\"\n",
    "labelPath = \"./data/cifar10_label.npy\"\n",
    "dataset = Dataset(cleanPath=cleanPath, attackPath=attackPath, labelPath=labelPath, net=target, device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ID(target=target).to(device)\n",
    "model.freezeTarget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean acc:\n",
      "Accuracy 92.61000061035156\n",
      "attack:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liyanni/1307/zwh/IHD/models.py:79: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629431274/work/aten/src/ATen/native/TensorIterator.cpp:918.)\n",
      "  y = torch.add(noise, inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 42.09000015258789\n",
      "attack:  1\n",
      "Accuracy 36.64999771118164\n",
      "attack:  2\n",
      "Accuracy 28.51999855041504\n",
      "attack:  3\n",
      "Accuracy 45.56999969482422\n",
      "attack:  4\n",
      "Accuracy 44.55999755859375\n",
      "attack:  5\n",
      "Accuracy 43.209999084472656\n",
      "attack:  6\n",
      "Accuracy 43.439998626708984\n",
      "attack:  7\n",
      "Accuracy 38.71999740600586\n",
      "attack:  8\n",
      "Accuracy 32.56999969482422\n"
     ]
    }
   ],
   "source": [
    "print(\"clean acc:\")\n",
    "test(net=target, testGen=dataset.testGen(0, clean=True))\n",
    "for i in range(9):\n",
    "    print(\"attack: \", i)\n",
    "    test(net=model, testGen=dataset.testGen(i, clean=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1  loss: 6.455\n",
      "epoch: 1  loss: 4.761\n",
      "epoch: 1  loss: 4.083\n",
      "epoch: 1  loss: 3.645\n",
      "epoch: 1  loss: 3.621\n",
      "epoch: 1  loss: 3.283\n",
      "epoch: 1  loss: 3.170\n",
      "epoch: 1  loss: 2.768\n",
      "epoch: 1  loss: 2.572\n",
      "epoch: 1  loss: 2.587\n",
      "epoch: 1  loss: 2.549\n",
      "epoch: 1  loss: 2.451\n",
      "epoch: 2  loss: 2.371\n",
      "epoch: 2  loss: 2.315\n",
      "epoch: 2  loss: 2.224\n",
      "epoch: 2  loss: 2.354\n",
      "epoch: 2  loss: 2.239\n",
      "epoch: 2  loss: 1.953\n",
      "epoch: 2  loss: 2.199\n",
      "epoch: 2  loss: 2.024\n",
      "epoch: 2  loss: 2.112\n",
      "epoch: 2  loss: 2.145\n",
      "epoch: 2  loss: 2.047\n",
      "epoch: 2  loss: 2.105\n",
      "epoch: 3  loss: 2.064\n",
      "epoch: 3  loss: 1.970\n",
      "epoch: 3  loss: 1.892\n",
      "epoch: 3  loss: 2.140\n",
      "epoch: 3  loss: 2.001\n",
      "epoch: 3  loss: 1.823\n",
      "epoch: 3  loss: 1.949\n",
      "epoch: 3  loss: 1.847\n",
      "epoch: 3  loss: 1.931\n",
      "epoch: 3  loss: 2.115\n",
      "epoch: 3  loss: 1.921\n",
      "epoch: 3  loss: 1.968\n",
      "epoch: 4  loss: 1.808\n",
      "epoch: 4  loss: 1.896\n",
      "epoch: 4  loss: 1.827\n",
      "epoch: 4  loss: 1.913\n",
      "epoch: 4  loss: 1.758\n",
      "epoch: 4  loss: 1.673\n",
      "epoch: 4  loss: 1.730\n",
      "epoch: 4  loss: 1.625\n",
      "epoch: 4  loss: 1.733\n",
      "epoch: 4  loss: 1.640\n",
      "epoch: 4  loss: 1.696\n",
      "epoch: 4  loss: 1.751\n",
      "epoch: 5  loss: 1.633\n",
      "epoch: 5  loss: 1.740\n",
      "epoch: 5  loss: 1.510\n",
      "epoch: 5  loss: 1.680\n",
      "epoch: 5  loss: 1.603\n",
      "epoch: 5  loss: 1.529\n",
      "epoch: 5  loss: 1.570\n",
      "epoch: 5  loss: 1.521\n",
      "epoch: 5  loss: 1.590\n",
      "epoch: 5  loss: 1.551\n",
      "epoch: 5  loss: 1.528\n",
      "epoch: 5  loss: 1.584\n",
      "epoch: 6  loss: 1.480\n",
      "epoch: 6  loss: 1.474\n",
      "epoch: 6  loss: 1.353\n",
      "epoch: 6  loss: 1.483\n",
      "epoch: 6  loss: 1.419\n",
      "epoch: 6  loss: 1.286\n",
      "epoch: 6  loss: 1.405\n",
      "epoch: 6  loss: 1.348\n",
      "epoch: 6  loss: 1.488\n",
      "epoch: 6  loss: 1.430\n",
      "epoch: 6  loss: 1.397\n",
      "epoch: 6  loss: 1.450\n",
      "epoch: 7  loss: 1.325\n",
      "epoch: 7  loss: 1.407\n",
      "epoch: 7  loss: 1.303\n",
      "epoch: 7  loss: 1.375\n",
      "epoch: 7  loss: 1.306\n",
      "epoch: 7  loss: 1.304\n",
      "epoch: 7  loss: 1.354\n",
      "epoch: 7  loss: 1.340\n",
      "epoch: 7  loss: 1.296\n",
      "epoch: 7  loss: 1.312\n",
      "epoch: 7  loss: 1.262\n",
      "epoch: 7  loss: 1.312\n",
      "epoch: 8  loss: 1.231\n",
      "epoch: 8  loss: 1.364\n",
      "epoch: 8  loss: 1.264\n",
      "epoch: 8  loss: 1.295\n",
      "epoch: 8  loss: 1.344\n",
      "epoch: 8  loss: 1.188\n",
      "epoch: 8  loss: 1.177\n",
      "epoch: 8  loss: 1.233\n",
      "epoch: 8  loss: 1.184\n",
      "epoch: 8  loss: 1.224\n",
      "epoch: 8  loss: 1.121\n",
      "epoch: 8  loss: 1.204\n",
      "epoch: 9  loss: 1.205\n",
      "epoch: 9  loss: 1.233\n",
      "epoch: 9  loss: 1.136\n",
      "epoch: 9  loss: 1.213\n",
      "epoch: 9  loss: 1.194\n",
      "epoch: 9  loss: 1.092\n",
      "epoch: 9  loss: 1.157\n",
      "epoch: 9  loss: 1.166\n",
      "epoch: 9  loss: 1.171\n",
      "epoch: 9  loss: 1.157\n",
      "epoch: 9  loss: 1.136\n",
      "epoch: 9  loss: 1.186\n",
      "epoch: 10  loss: 1.196\n",
      "epoch: 10  loss: 1.165\n",
      "epoch: 10  loss: 1.017\n",
      "epoch: 10  loss: 1.122\n",
      "epoch: 10  loss: 1.147\n",
      "epoch: 10  loss: 1.090\n",
      "epoch: 10  loss: 1.010\n",
      "epoch: 10  loss: 0.993\n",
      "epoch: 10  loss: 1.150\n",
      "epoch: 10  loss: 1.115\n",
      "epoch: 10  loss: 1.054\n",
      "epoch: 10  loss: 1.141\n",
      "clean\n",
      "Accuracy 89.79000091552734\n",
      "attack:  0\n",
      "Accuracy 88.4000015258789\n",
      "attack:  1\n",
      "Accuracy 85.86000061035156\n",
      "attack:  2\n",
      "Accuracy 73.37999725341797\n",
      "attack:  3\n",
      "Accuracy 89.50999450683594\n",
      "attack:  4\n",
      "Accuracy 89.6199951171875\n",
      "attack:  5\n",
      "Accuracy 89.27999877929688\n",
      "attack:  6\n",
      "Accuracy 89.1199951171875\n",
      "attack:  7\n",
      "Accuracy 86.75999450683594\n",
      "attack:  8\n",
      "Accuracy 82.33999633789062\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "train(net=model, epoch=10, dataset=dataset, enhance=False)\n",
    "# testing\n",
    "print(\"clean\")\n",
    "test(net=model, testGen=dataset.testGen(0, clean=True))\n",
    "for i in range(9):\n",
    "    print(\"attack: \", i)\n",
    "    test(net=model, testGen=dataset.testGen(i, clean=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
